# src/ â€” Backend Source Code

## Overview

The `src/` folder contains all backend logic for the Voice AI complaint handling system.

---

## Folder Structure

```
src/
â”œâ”€â”€ server.ts           # Express server entry point + /voice endpoint
â”œâ”€â”€ agent/              # Complaint handling AI agent
â”‚   â”œâ”€â”€ agent.ts        # Main agent logic (orchestrates the flow)
â”‚   â””â”€â”€ states.ts       # Agent state types & complaint classifications
â”œâ”€â”€ voice/              # Audio processing (Azure Speech Services)
â”‚   â”œâ”€â”€ stt.ts          # Speech-to-Text (audio â†’ text)
â”‚   â””â”€â”€ tts.ts          # Text-to-Speech (text â†’ audio)
â”œâ”€â”€ metrics/            # Logging & monitoring
â”‚   â””â”€â”€ logger.ts       # Performance metrics & decision logging
â””â”€â”€ README.md           # This file
```

---

## What Each Part Does

### ðŸ“¡ `server.ts`
- **Purpose**: Express server entry point
- **Responsibilities**:
  - Starts the Node.js server
  - Defines the `POST /voice` endpoint
  - Receives requests from the frontend
  - Orchestrates STT â†’ Agent â†’ TTS pipeline
  - Returns text + audio responses

### ðŸ¤– `agent/` â€” Complaint Agent
- **What it is**: The "brain" of the system
- **How it works**:
  1. Receives user complaint (text or transcribed audio)
  2. Classifies complaint type (APPOINTMENT, BILLING, OTHER)
  3. Optionally asks a follow-up question
  4. Generates an empathetic response
  5. Returns structured decision

**Files**:
- `states.ts`: TypeScript types for agent state machine
- `agent.ts`: Implements the three-state flow (CLASSIFY â†’ COLLECT â†’ RESPOND)

### ðŸŽ¤ `voice/` â€” Audio Processing
- **What it is**: Integration with Azure Speech Services
- **Responsibilities**:

  **`stt.ts` (Speech-to-Text)**:
  - Converts audio files to text using Azure Speech API
  - Input: Audio buffer (wav, mp3, etc.)
  - Output: Transcribed text string

  **`tts.ts` (Text-to-Speech)**:
  - Converts AI response text to audio using Azure Speech API
  - Input: Text string
  - Output: Audio buffer (base64 for frontend playback)

### ðŸ“Š `metrics/`
- **What it is**: Logging & performance tracking
- **Tracks**:
  - Total request latency
  - LLM processing time
  - STT processing time (if used)
  - TTS processing time (if used)
  - Complaint type classified
  - Agent state transitions
- **Output**: Console logs (simple, no database)

---

## Request Flow

```
Browser Request
    â†“
POST /voice (server.ts)
    â†“
Audio Input? â†’ STT (voice/stt.ts) â†’ Text
    â†“
Agent Process (agent/agent.ts)
    â”œâ”€ Classify complaint type
    â”œâ”€ Ask follow-up (optional)
    â””â”€ Generate response
    â†“
TTS (voice/tts.ts) â†’ Audio from response
    â†“
Log Metrics (metrics/logger.ts)
    â†“
Return { textResponse, audioBase64, complaintType }
    â†“
Browser Displays + Plays Audio
```

---

## Data Types

See `agent/states.ts` for all TypeScript interfaces:

```typescript
AgentState:  CLASSIFY_COMPLAINT | COLLECT_DETAILS | RESPOND
ComplaintType: APPOINTMENT | BILLING | OTHER
AgentContext: { userInput, complaintType, state, confidence, response }
RequestMetrics: { totalLatency, llmLatency, sttLatency, ttsLatency, ... }
```

---

## Implementation Checklist

- [ ] `server.ts` â€” Express setup + /voice endpoint
- [ ] `agent/agent.ts` â€” Complaint classification & response generation
- [ ] `voice/stt.ts` â€” Azure Speech-to-Text integration
- [ ] `voice/tts.ts` â€” Azure Text-to-Speech integration
- [ ] `metrics/logger.ts` â€” Request logging

---

## Environment Variables

All Azure API keys go in `.env`:

```
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=
AZURE_SPEECH_KEY=
AZURE_SPEECH_REGION=
```

---

## Notes

- All files use TypeScript
- Simple, readable functions (no over-abstraction)
- Azure APIs are called via SDK / HTTP requests
- No local model downloads
- Metrics logged to console only
